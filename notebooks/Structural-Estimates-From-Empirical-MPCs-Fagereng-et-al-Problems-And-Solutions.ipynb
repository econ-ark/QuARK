{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Structural Estimates From Empirical Results\n",
    "\n",
    "This notebook conducts a quick and dirty structural estimation based on Table 9 of \"MPC Heterogeneity and Household Balance Sheets\" by Fagereng, Holm, and Natvik <cite data-cite=\"6202365/SUE56C4B\"></cite>, who use Norweigian administrative data on income, household assets, and lottery winnings to examine the MPC from transitory income shocks (lottery prizes).  Their Table 9 reports an estimated MPC broken down by quartiles of bank deposits and\n",
    "prize size; this table is reproduced here as $\\texttt{MPC_target_base}$.  In this demo, we use the Table 9 estimates as targets in a simple structural estimation, seeking to minimize the sum of squared differences between simulated and estimated MPCs by changing the (uniform) distribution of discount factors.  The essential question is how well their results be rationalized by a simple one-asset consumption-saving model.  \n",
    "\n",
    "\n",
    "The function that estimates discount factors includes several options for estimating different specifications:\n",
    "\n",
    "1. TypeCount : Integer number of discount factors in discrete distribution; can be set to 1 to turn off _ex ante_ heterogeneity (and to discover that the model has no chance to fit the data well without such heterogeneity).\n",
    "2. AdjFactor : Scaling factor for the target MPCs; user can try to fit estimated MPCs scaled down by (e.g.) 50%.\n",
    "3. T_kill    : Maximum number of years the (perpetually young) agents are allowed to live.  Because this is quick and dirty, it's also the number of periods to simulate.\n",
    "4. Splurge   : Amount of lottery prize that an individual will automatically spend in a moment of excitement (perhaps ancient tradition in Norway requires a big party when you win the lottery), before beginning to behave according to the optimal consumption function.  The patterns in Table 9 can be fit much better when this is set around \\$700 --> 0.7.  That doesn't seem like an unreasonable amount of money to spend on a memorable party.\n",
    "5. do_secant : Boolean indicator for whether to use \"secant MPC\", which is average MPC over the range of the prize.  MNW believes authors' regressions are estimating this rather than point MPC.  When False, structural estimation uses point MPC after receiving prize.  NB: This is incompatible with Splurge > 0.\n",
    "6. drop_corner : Boolean for whether to include target MPC in the top left corner, which is greater than 1.  Authors discuss reasons why the MPC from a transitory shock *could* exceed 1.  Option is included here because this target tends to push the estimate around a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import python tools\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import needed tools from HARK\n",
    "\n",
    "from HARK.utilities import approxUniform, getPercentiles\n",
    "from HARK.parallel import multiThreadCommands\n",
    "from HARK.estimation import minimizeNelderMead\n",
    "from HARK.ConsumptionSaving.ConsIndShockModel import *\n",
    "from HARK.cstwMPC.SetupParamsCSTW import init_infinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Set key problem-specific parameters\n",
    "\n",
    "TypeCount = 8    # Number of consumer types with heterogeneous discount factors\n",
    "AdjFactor = 1.0  # Factor by which to scale all of MPCs in Table 9\n",
    "T_kill = 100     # Don't let agents live past this age\n",
    "Splurge = 0.75    # Consumers automatically spend this amount of any lottery prize\n",
    "do_secant = True # If True, calculate MPC by secant, else point MPC\n",
    "drop_corner = 0.0 # If True, ignore upper left corner when calculating distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Set standard HARK parameter values\n",
    "\n",
    "base_params = deepcopy(init_infinite)\n",
    "base_params['LivPrb'] = [0.975]\n",
    "base_params['Rfree'] = 1.04/base_params['LivPrb'][0]\n",
    "base_params['PermShkStd'] = [0.1]\n",
    "base_params['TranShkStd'] = [0.1]\n",
    "base_params['T_age'] = T_kill # Kill off agents if they manage to achieve T_kill working years\n",
    "base_params['AgentCount'] = 10000\n",
    "base_params['pLvlInitMean'] = np.log(23.72) # From Table 1, in thousands of USD\n",
    "base_params['T_sim'] = T_kill  # No point simulating past when agents would be killed off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define the MPC targets from Fagereng et al Table 9; element i,j is lottery quartile i, deposit quartile j\n",
    "\n",
    "MPC_target_base = np.array([[1.047, 0.745, 0.720, 0.490],\n",
    "                            [0.762, 0.640, 0.559, 0.437],\n",
    "                            [0.663, 0.546, 0.390, 0.386],\n",
    "                            [0.354, 0.325, 0.242, 0.216]])\n",
    "MPC_target = AdjFactor*MPC_target_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define the four lottery sizes, in thousands of USD; these are eyeballed centers/averages\n",
    "\n",
    "lottery_size = np.array([1.625, 3.3741, 7.129, 40.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "code_folding": [],
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Make several consumer types to be used during estimation\n",
    "\n",
    "BaseType = IndShockConsumerType(**base_params)\n",
    "EstTypeList = []\n",
    "for j in range(TypeCount):\n",
    "    EstTypeList.append(deepcopy(BaseType))\n",
    "    EstTypeList[-1](seed = j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "\n",
    "def FagerengObjFunc(center,spread,verbose=False):\n",
    "    '''\n",
    "    Objective function for the quick and dirty structural estimation to fit\n",
    "    Fagereng, Holm, and Natvik's Table 9 results with a basic infinite horizon\n",
    "    consumption-saving model (with permanent and transitory income shocks).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    center : float\n",
    "        Center of the uniform distribution of discount factors.\n",
    "    spread : float\n",
    "        Width of the uniform distribution of discount factors.\n",
    "    verbose : bool\n",
    "        When True, print to screen MPC table for these parameters.  When False,\n",
    "        print (center, spread, distance).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance : float\n",
    "        Euclidean distance between simulated MPCs and (adjusted) Table 9 MPCs.\n",
    "    '''\n",
    "    # Give our consumer types the requested discount factor distribution\n",
    "    beta_set = approxUniform(N=TypeCount,bot=center-spread,top=center+spread)[1]\n",
    "    for j in range(TypeCount):\n",
    "        EstTypeList[j](DiscFac = beta_set[j])\n",
    "\n",
    "    # Solve and simulate all consumer types, then gather their wealth levels\n",
    "    multiThreadCommands(EstTypeList,['solve()','initializeSim()','simulate()','unpackcFunc()'])\n",
    "    WealthNow = np.concatenate([ThisType.aLvlNow for ThisType in EstTypeList])\n",
    "\n",
    "    # Get wealth quartile cutoffs and distribute them to each consumer type\n",
    "    quartile_cuts = getPercentiles(WealthNow,percentiles=[0.25,0.50,0.75])\n",
    "    for ThisType in EstTypeList:\n",
    "        WealthQ = np.zeros(ThisType.AgentCount,dtype=int)\n",
    "        for n in range(3):\n",
    "            WealthQ[ThisType.aLvlNow > quartile_cuts[n]] += 1\n",
    "        ThisType(WealthQ = WealthQ)\n",
    "\n",
    "    # Keep track of MPC sets in lists of lists of arrays\n",
    "    MPC_set_list = [ [[],[],[],[]],\n",
    "                     [[],[],[],[]],\n",
    "                     [[],[],[],[]],\n",
    "                     [[],[],[],[]] ]\n",
    "\n",
    "    # Calculate the MPC for each of the four lottery sizes for all agents\n",
    "    for ThisType in EstTypeList:\n",
    "        ThisType.simulate(1)\n",
    "        c_base = ThisType.cNrmNow\n",
    "        MPC_this_type = np.zeros((ThisType.AgentCount,4))\n",
    "        \n",
    "        for k in range(4): # Get MPC for all agents of this type\n",
    "            Llvl = lottery_size[k]\n",
    "            Lnrm = Llvl/ThisType.pLvlNow\n",
    "            if do_secant:\n",
    "                SplurgeNrm = Splurge/ThisType.pLvlNow\n",
    "                mAdj = ThisType.mNrmNow + Lnrm - SplurgeNrm\n",
    "                cAdj = ThisType.cFunc[0](mAdj) + SplurgeNrm\n",
    "                MPC_this_type[:,k] = (cAdj - c_base)/Lnrm\n",
    "            else:\n",
    "                mAdj = ThisType.mNrmNow + Lnrm\n",
    "                MPC_this_type[:,k] = cAdj = ThisType.cFunc[0].derivative(mAdj)\n",
    "\n",
    "        # Sort the MPCs into the proper MPC sets\n",
    "        for q in range(4):\n",
    "            these = ThisType.WealthQ == q\n",
    "            for k in range(4):\n",
    "                MPC_set_list[k][q].append(MPC_this_type[these,k])\n",
    "\n",
    "    # Calculate average within each MPC set\n",
    "    simulated_MPC_means = np.zeros((4,4))\n",
    "    for k in range(4):\n",
    "        for q in range(4):\n",
    "            MPC_array = np.concatenate(MPC_set_list[k][q])\n",
    "            simulated_MPC_means[k,q] = np.mean(MPC_array)\n",
    "\n",
    "    # Calculate Euclidean distance between simulated MPC averages and Table 9 targets\n",
    "    diff = simulated_MPC_means - MPC_target\n",
    "    if drop_corner:\n",
    "        diff[0,0] = 0.0\n",
    "    distance = np.sqrt(np.sum((diff)**2))\n",
    "    if verbose:\n",
    "        print(simulated_MPC_means)\n",
    "    else:\n",
    "        print (center, spread, distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92 0.03 0.5728359985856661\n",
      "0.9660000000000001 0.03 1.0865233968407848\n",
      "0.92 0.0315 0.5707029208693234\n",
      "0.874 0.0315 0.5023837137685602\n",
      "0.8280000000000001 0.03225 0.6060752772205258\n",
      "0.874 0.033 0.4997399788082691\n",
      "0.8509999999999998 0.0345 0.5434101687543998\n",
      "0.828 0.033 0.6052681667980814\n",
      "0.897 0.031875 0.4914268289260696\n",
      "0.8969999999999999 0.033375 0.4886712751120285\n",
      "0.9084999999999999 0.034312499999999996 0.5119247641785709\n",
      "0.92 0.03225 0.5696710469907433\n",
      "0.8855 0.0328125 0.48776600094040784\n",
      "0.8854999999999997 0.03431250000000001 0.4849927681594527\n",
      "0.8797499999999996 0.035531250000000014 0.4875623664057135\n",
      "0.8739999999999998 0.033750000000000016 0.4985091271811477\n",
      "0.8912499999999999 0.033468750000000005 0.4851906123183567\n",
      "0.8912499999999997 0.034968750000000014 0.4823916520349069\n",
      "0.8941249999999994 0.03604687500000002 0.48151546386843297\n",
      "0.8883749999999992 0.036890625000000024 0.47889436229502247\n",
      "0.8869374999999988 0.03860156250000003 0.47591510716208757\n",
      "0.8955624999999985 0.040335937500000044 0.4743812064265969\n",
      "0.9005937499999979 0.04334765625000006 0.4749373012890804\n",
      "0.8883749999999979 0.04289062500000006 0.46682392914331594\n",
      "0.8854999999999973 0.046312500000000076 0.46006600651243434\n",
      "0.894124999999997 0.048046875000000086 0.4568732238732536\n",
      "0.8977187499999961 0.05276953125000011 0.4504128491536024\n",
      "0.8876562499999949 0.058746093750000145 0.4293462840665867\n",
      "0.8837031249999932 0.06795117187500019 0.4083855238973414\n",
      "0.895921874999992 0.07440820312500022 0.4215705958676757\n",
      "0.881906249999989 0.08958984375000029 0.37944203226267226\n",
      "0.8739999999999855 0.10800000000000037 0.36648846402836904\n",
      "0.8617812499999866 0.10154296875000034 0.3638725371901755\n",
      "0.8447109374999839 0.11511035156250041 0.3831008986263425\n",
      "0.8520781249999789 0.14159179687500054 0.37010948194069654\n",
      "0.8599843749999825 0.12318164062500044 0.3588645096041773\n",
      "0.8477656249999836 0.1167246093750004 0.37177047071219677\n",
      "0.867441406249985 0.11018115234375038 0.35903323350052396\n",
      "0.865644531249981 0.1318198242187505 0.3760519084930996\n",
      "0.8627470703124852 0.10911218261718787 0.35783003594052154\n",
      "0.8552900390624828 0.12211267089843793 0.35917794263882763\n",
      "0.8644035644531094 0.11316403198242227 0.3574345708798343\n",
      "0.8671662597656122 0.0990945739746097 0.36210730061174873\n",
      "0.8617798461913899 0.11715987396240275 0.3576298736165318\n",
      "0.8634363403320141 0.12121172332763715 0.3599516483275793\n",
      "0.8629193878173674 0.11213706779480019 0.3572186412520107\n",
      "0.8655431060790868 0.1081412258148197 0.3581055304121865\n",
      "0.8627206611633141 0.11490521192550698 0.35715395241113956\n",
      "0.8612364845275722 0.1138782477378849 0.357151074522974\n",
      "0.8596529445648038 0.11423535561561624 0.35758359863807526\n",
      "0.861037757873519 0.11664639186859167 0.3573264855726373\n",
      "0.8624489803314053 0.11326439881324807 0.35706684842179137\n",
      "0.8609648036956633 0.11223743462562599 0.3575825857604902\n",
      "0.8622816967964014 0.11423826760053674 0.35703693587100344\n",
      "0.8634941926002346 0.11362441867589991 0.3571339653731552\n",
      "0.8629297655820689 0.11368787594139615 0.3570038775145033\n",
      "0.8627624820470652 0.11466174472868482 0.3570736796295925\n",
      "0.8625273557603202 0.11361373529210725 0.35709154787354525\n",
      "0.8626057311892352 0.11396307177096644 0.35701387905974424\n",
      "0.8626893729567371 0.11347613737732211 0.3571064689716482\n",
      "0.862846123814567 0.1141748103350405 0.35711211792261294\n",
      "0.8627285606711945 0.1136508056167517 0.35706372307138384\n",
      "0.8628069361001096 0.1140001420956109 0.35710630713984826\n",
      "0.8627481545284232 0.1137381397364665 0.35705061737103694\n",
      "0.8627873422428809 0.1139128079758961 0.35705808247009263\n",
      "0.8627579514570376 0.11378180679632391 0.3569805410320015\n",
      "0.8630819858498713 0.11350661096675362 0.35709591424677545\n",
      "0.8627247948543942 0.11384895656991323 0.3570044301454666\n",
      "0.8629629221847123 0.11362072616780683 0.3570592940521079\n",
      "0.8627843266869737 0.11379189896938663 0.35698901544387485\n",
      "0.8626125125619424 0.11388582982431439 0.35701501054607787\n",
      "0.8628504523270373 0.1137373644121257 0.35698367294345285\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.356981\n",
      "         Iterations: 35\n",
      "         Function evaluations: 72\n",
      "Time to estimate is 415.4652011394501 seconds.\n",
      "Finished estimating for scaling factor of 1.0 and \"splurge amount\" of $750.0\n",
      "Optimal (beta,nabla) is [0.86275795 0.11378181], simulated MPCs are:\n",
      "[[0.78791058 0.75721641 0.70740854 0.58335306]\n",
      " [0.68018181 0.64008361 0.56962574 0.39541177]\n",
      " [0.60439296 0.5651436  0.48660528 0.29588357]\n",
      " [0.42933477 0.40248463 0.33554083 0.18337192]]\n",
      "Distance from Fagereng et al Table 9 is 0.3569805410320015\n"
     ]
    }
   ],
   "source": [
    "# Conduct the estimation\n",
    "\n",
    "guess = [0.92,0.03]\n",
    "f_temp = lambda x : FagerengObjFunc(x[0],x[1])\n",
    "opt_params = minimizeNelderMead(f_temp, guess, verbose=True)\n",
    "print('Finished estimating for scaling factor of ' + str(AdjFactor) + ' and \"splurge amount\" of $' + str(1000*Splurge))\n",
    "print('Optimal (beta,nabla) is ' + str(opt_params) + ', simulated MPCs are:')\n",
    "dist = FagerengObjFunc(opt_params[0],opt_params[1],True)\n",
    "print('Distance from Fagereng et al Table 9 is ' + str(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM\n",
    "\n",
    "See what happens if you do not allow a splurge amount at all.  Hint: Think about how this question relates to the `drop_corner` option.\n",
    "\n",
    "Explain why you get the results you do, and comment on possible interpretations of the \"splurge\" that might be consistent with economic theory.    \n",
    "Hint: What the authors are able to measure is actually the marginal propensity to EXPEND, not the marginal propensity to CONSUME as it is defined in our benchmark model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put your solution here\n",
    "\n",
    "The authors estimates an average increase in consumption expenditure and build hypotese why it is consistent with how MPCs are extimated and interpreted in the literature. A point estimate of beta 1 will be pulled toward the MPCs of winner of relatevely high size. The authors estimates how large fraction of the lottery prize the average lottery winner in the sample spends on consumption within the year of winning. \n",
    " \n",
    "The \"splurge\" is interpreted here as a state when consumers automatically spend the amount of any lottery prize. \n",
    "Compare to the incomplete markets models where households face uninsurable idiosyncratic risk and a borrowing constraints, they acqure a buffer stock of capital in order to prevent the constraint from binding, Then the wealth level is the main determinant of the households' MPC then their net wealth level. However, the authors argues that their findings indicate that the net wealth is important once liquidity is controlled for. These findings are in conflict with the interpretation from the buffer stock savings models. \n",
    "\n",
    "\"Drop corner\" is the boolean for whether to include target MPC in the top left corner, which is greater than 1. MPC from the transitory shock could exceed 1. However in case if we do not allow a splurge amount at all as a shock size, then the response can differ but not so much. \"Drop corner\" option can push estimates and show what happened if variabel \"splurge\" is equal 0 or 1. Lets look at the 3 scenario: splurge=0,75 and drop corner=1; splurge=0,0 and drop corner=0 and splurge=0,75 and drop corner=0\n",
    "\n",
    "Scenario 1\n",
    "Splurge=0,0\n",
    "drop corner=0\n",
    "\n",
    "\n",
    "[[0.77361336 0.68317127 0.56461082 0.40476962]\n",
    " [0.74354975 0.66482752 0.55301552 0.39626053]\n",
    " [0.70353353 0.63512154 0.5305429  0.3793119 ]\n",
    " [0.5613238  0.50428804 0.4125933  0.29261249]]\n",
    " Distance from Fagereng et al Table 9 is 0.5021025392131131\n",
    " Optimal (beta,nabla) is [0.78981881 0.16098057]\n",
    " \n",
    "When individuals spend nothing and drop corner is zero, the calculated distance from the target values is the biggest among all scenarios. It is looks like the worst scenario as it shows that if there is no splurge it is difficut for the model to match calculated high MPC to the lower wealth qualriles. \n",
    "\n",
    "Scenario 2\n",
    "Splurge=0,75\n",
    "drop corner=1\n",
    " \n",
    " [[0.77190491 0.74430021 0.70140645 0.59364668]\n",
    " [0.65701731 0.62152995 0.56087767 0.4084999 ]\n",
    " [0.57760029 0.54386887 0.47673001 0.31037197]\n",
    " [0.39990788 0.37986204 0.32617723 0.19521486]]\n",
    " Distance from Fagereng et al Table 9 is 0.23757458381351887\n",
    "Optimal (beta,nabla) is [0.87162876 0.09774449]\n",
    "\n",
    "In this scenario beta is the largest, nabla and distnace is the lowest. Probably the best scenario for data simulation. The model shows that if there are some expenditure and drop corner=1, then the distance between the simulated MPC and target MPC is low. It shows that relative high beta allows the model better to match simulated MPC to the target MPC . \n",
    " \n",
    "Scenario 3\n",
    "Splurge=0,75\n",
    "drop corner=0\n",
    "\n",
    "[[0.78791058 0.75721641 0.70740854 0.58335306]\n",
    " [0.68018181 0.64008361 0.56962574 0.39541177]\n",
    " [0.60439296 0.5651436  0.48660528 0.29588357]\n",
    " [0.42933477 0.40248463 0.33554083 0.18337192]]\n",
    "Distance from Fagereng et al Table 9 is 0.3569805410320015\n",
    "Optimal (beta,nabla) is [0.86275795 0.11378181]\n",
    "\n",
    "This scenario is the nest best. The beta is some lower than in the previous scenario when the drop corner=1. Now it we use the drop corner=0, then high beta also allows to match simulated MPC to the target MPC when simulated MPC is some lower than in the previous scenario. But this scenario shows that if we exclude the drop corner the model might work better to match relative high simulated MPC to their target level.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM\n",
    "\n",
    "Call the _Marginal Propensity to Continue Consuming_ (MPCC) in year `t+n` the proportion of lottery winnings that get spent in year `t+n`.  That is, if consumption is higher in year `t+2` by an amount corresponding to 14 percent of lottery winnings, we would say  _the MPCC in t+2 is 14 percent.\n",
    "\n",
    "For the baseline version of the model with the \"splurge\" component, calculate the MPCC's for years `t+1` through `t+3` and plot them together with the MPC in the first year (including the splurge component)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MPC for t+0 \n",
      " [[0.78567857 0.75529075 0.70422096 0.57434956]\n",
      " [0.67596163 0.63714129 0.56530426 0.38258846]\n",
      " [0.59784702 0.56132056 0.48191713 0.28327884]\n",
      " [0.42130211 0.39851849 0.33303836 0.17886577]]\n",
      "\n",
      "\n",
      "The MPCC for t+1 \n",
      " [[0.15017068 0.17156936 0.19343695 0.20817884]\n",
      " [0.20508986 0.21869224 0.22489322 0.18006798]\n",
      " [0.23801211 0.24456214 0.24006372 0.16486564]\n",
      " [0.26434538 0.2607976  0.23505038 0.14107942]]\n",
      "\n",
      "\n",
      "The MPCC for t+2 \n",
      " [[0.08420981 0.11176419 0.16050027 0.28118279]\n",
      " [0.10095318 0.12195854 0.15508628 0.19716259]\n",
      " [0.11762377 0.13275262 0.15614253 0.15623452]\n",
      " [0.16672645 0.17023348 0.17019776 0.1233315 ]]\n",
      "\n",
      "\n",
      "The MPCC for t+3 \n",
      " [[0.05853968 0.08205659 0.13928964 0.34976285]\n",
      " [0.05648862 0.07443471 0.11433888 0.21729341]\n",
      " [0.06136254 0.07528211 0.106014   0.15338417]\n",
      " [0.10061274 0.10719368 0.12161918 0.10912477]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Put your solution here\n",
    "def FagerengFutureObjFunc(center,spread,verbose=False):\n",
    "\n",
    "    # Give our consumer types the requested discount factor distribution\n",
    "    beta_set = approxUniform(N=TypeCount,bot=center-spread,top=center+spread)[1]\n",
    "    for j in range(TypeCount):\n",
    "        EstTypeList[j](DiscFac = beta_set[j])\n",
    "        # add tracking vars to each Type\n",
    "        EstTypeList[j].track_vars = ['aNrmNow','cNrmNow','mNrmNow','pLvlNow','PermShkNow','TranShkNow']\n",
    "        \n",
    "    #aNrmNow - A 1D array of end-of-period assets; \n",
    "    #cNrmNow  – Arrays with consumption points for interpolation now;\n",
    "    #mNrmNow  – Arrays with corresponding market resource points for interpolation now;\n",
    "    #pLvlNow - Arrays with permanent income levels, listed by each ConsumerType in self.agents.\n",
    "    #PermShkNow - Arrays with permanent income shocks, listed by each ConsumerType in self.agents.\n",
    "    #TranShkNow - Arrays with transitory income shocks, listed by each ConsumerType in self.agents.\n",
    "     \n",
    "      # Bounds for axis with size 100\n",
    "    Start_Period = 95;\n",
    "    # Solve and simulate all consumer types, then gather their wealth levels\n",
    "    multiThreadCommands(EstTypeList,['solve()','initializeSim()','simulate(95)','unpackcFunc()'])\n",
    "    WealthNow = np.concatenate([ThisType.aLvlNow for ThisType in EstTypeList])\n",
    "    Rfree = base_params['Rfree']\n",
    "\n",
    "    # Get wealth quartile cutoffs and distribute them to each consumer type\n",
    "    quartile_cuts = getPercentiles(WealthNow,percentiles=[0.25,0.50,0.75])\n",
    "    for ThisType in EstTypeList:\n",
    "        WealthQ = np.zeros(ThisType.AgentCount,dtype=int)\n",
    "        for n in range(3):\n",
    "            WealthQ[ThisType.aLvlNow > quartile_cuts[n]] += 1\n",
    "        ThisType(WealthQ = WealthQ)\n",
    "\n",
    "    # Keep track of MPC sets in lists of lists of arrays\n",
    "    MPC_set_list = [ [[],[],[],[]],\n",
    "                     [[],[],[],[]],\n",
    "                     [[],[],[],[]],\n",
    "                     [[],[],[],[]] ]\n",
    "    MPC_set_list_t1 = deepcopy(MPC_set_list)\n",
    "    MPC_set_list_t2 = deepcopy(MPC_set_list)\n",
    "    MPC_set_list_t3 = deepcopy(MPC_set_list)\n",
    "\n",
    "   \n",
    "    # Calculate the MPC for each of the four lottery sizes for all agents\n",
    "    \n",
    "    #for ThisType in EstTypeList:\n",
    "       # ThisType.simulate(1)\n",
    "        #c_base = ThisType.cNrmNow\n",
    "        #MPC_this_type = np.zeros((ThisType.AgentCount,4))\n",
    "        \n",
    "    for ThisType in EstTypeList:\n",
    "        ThisType.simulate(4)\n",
    "        c_base_0 = ThisType.cNrmNow_hist[Start_Period]\n",
    "        c_base_t1 = ThisType.cNrmNow_hist[Start_Period+1]\n",
    "        c_base_t2 = ThisType.cNrmNow_hist[Start_Period+2]\n",
    "        c_base_t3 = ThisType.cNrmNow_hist[Start_Period+3]\n",
    "        \n",
    "        MPC_this_type = np.zeros((ThisType.AgentCount,4))\n",
    "        MPC_this_type_t1 = np.zeros((ThisType.AgentCount,4))\n",
    "        MPC_this_type_t2 = np.zeros((ThisType.AgentCount,4))\n",
    "        MPC_this_type_t3 = np.zeros((ThisType.AgentCount,4))\n",
    "    \n",
    "        for k in range(4): # Get MPC for all agents of this type       \n",
    "            Llvl = lottery_size[k]\n",
    "            Lnrm = Llvl/ThisType.pLvlNow_hist[Start_Period]     \n",
    "            SplurgeNrm = Splurge/ThisType.pLvlNow_hist[Start_Period]\n",
    "            mAdj = ThisType.mNrmNow_hist[Start_Period] + Lnrm - SplurgeNrm\n",
    "            cAdj = ThisType.cFunc[0](mAdj) + SplurgeNrm\n",
    "            MPC_this_type[:,k] = (cAdj - c_base_0) /Lnrm\n",
    "            \n",
    "            # MPC for t+1 \n",
    "            Llvl = lottery_size[k]\n",
    "            Lnrm = Llvl/ThisType.pLvlNow_hist[Start_Period+1]\n",
    "            aNrm_t0 = ThisType.mNrmNow_hist[Start_Period] + Lnrm - cAdj\n",
    "            aLvl_t0 = aNrm_t0*ThisType.pLvlNow_hist[Start_Period]\n",
    "            mLvl_t1 = aLvl_t0*Rfree + ThisType.TranShkNow_hist[Start_Period+1]*ThisType.pLvlNow_hist[Start_Period+1]\n",
    "            mNrm_t1 = mLvl_t1/ThisType.pLvlNow_hist[Start_Period+1]\n",
    "            cNrm_t1 = ThisType.cFunc[0](mNrm_t1)\n",
    "            MPC_this_type_t1[:,k] = (cNrm_t1 - c_base_t1) /Lnrm\n",
    "\n",
    "            # MPC for t+2 \n",
    "            Llvl = lottery_size[k]\n",
    "            Lnrm = Llvl/ThisType.pLvlNow_hist[Start_Period+2]\n",
    "            aNrm_t1 = mNrm_t1 - cNrm_t1;\n",
    "            aLvl_t1 = aNrm_t1*ThisType.pLvlNow_hist[Start_Period+1]\n",
    "            mLvl_t2 = aLvl_t1*Rfree + ThisType.TranShkNow_hist[Start_Period+2]*ThisType.pLvlNow_hist[Start_Period+2]\n",
    "            mNrm_t2 = mLvl_t2/ThisType.pLvlNow_hist[Start_Period+2]\n",
    "            cNrm_t2 = ThisType.cFunc[0](mNrm_t2)\n",
    "            MPC_this_type_t2[:,k] = (cNrm_t2 - c_base_t2) /Lnrm\n",
    "\n",
    "            # MPC for t+3 \n",
    "            Llvl = lottery_size[k]\n",
    "            Lnrm = Llvl/ThisType.pLvlNow_hist[Start_Period+3]\n",
    "            aNrm_t2 = mNrm_t2 - cNrm_t2;\n",
    "            aLvl_t2 = aNrm_t2*ThisType.pLvlNow_hist[Start_Period+2]\n",
    "            mLvl_t3 = aLvl_t2*Rfree + ThisType.TranShkNow_hist[Start_Period+3]*ThisType.pLvlNow_hist[Start_Period+3]\n",
    "            mNrm_t3 = mLvl_t3/ThisType.pLvlNow_hist[Start_Period+3]\n",
    "            cNrm_t3 = ThisType.cFunc[0](mNrm_t3)\n",
    "            MPC_this_type_t3[:,k] = (cNrm_t3 - c_base_t3) /Lnrm\n",
    "            \n",
    "\n",
    "        # Sort the MPCs into the proper MPC sets\n",
    "        for q in range(4):\n",
    "            these = ThisType.WealthQ == q\n",
    "            for k in range(4):\n",
    "                MPC_set_list[k][q].append(MPC_this_type[these,k])\n",
    "                MPC_set_list_t1[k][q].append(MPC_this_type_t1[these,k])\n",
    "                MPC_set_list_t2[k][q].append(MPC_this_type_t2[these,k])\n",
    "                MPC_set_list_t3[k][q].append(MPC_this_type_t3[these,k])\n",
    "\n",
    "    # Calculate average within each MPC set\n",
    "    simulated_MPC_means = np.zeros((4,4))\n",
    "    simulated_MPC_means_t1 = np.zeros((4,4))\n",
    "    simulated_MPC_means_t2 = np.zeros((4,4))\n",
    "    simulated_MPC_means_t3 = np.zeros((4,4))\n",
    "    for k in range(4):\n",
    "        for q in range(4):\n",
    "            MPC_array = np.concatenate(MPC_set_list[k][q])\n",
    "            simulated_MPC_means[k,q] = np.mean(MPC_array)\n",
    "            simulated_MPC_means_t1[k,q] = np.mean(np.concatenate(MPC_set_list_t1[k][q]))\n",
    "            simulated_MPC_means_t2[k,q] = np.mean(np.concatenate(MPC_set_list_t2[k][q]))\n",
    "            simulated_MPC_means_t3[k,q] = np.mean(np.concatenate(MPC_set_list_t3[k][q]))\n",
    "            \n",
    "    print('The MPC for t+0 \\n', simulated_MPC_means)\n",
    "    print('\\n')\n",
    "    print('The MPCC for t+1 \\n', simulated_MPC_means_t1)\n",
    "    print('\\n')\n",
    "    print('The MPCC for t+2 \\n', simulated_MPC_means_t2)\n",
    "    print('\\n')\n",
    "    print('The MPCC for t+3 \\n', simulated_MPC_means_t3)\n",
    "    print('\\n')\n",
    "   \n",
    "    # Calculate Euclidean distance between simulated MPC averages and Table 9 targets\n",
    "    diff = simulated_MPC_means - MPC_target\n",
    "    if drop_corner:\n",
    "        diff[0,0] = 0.0\n",
    "    distance = np.sqrt(np.sum((diff)**2))\n",
    "    return distance\n",
    "\n",
    "dist = FagerengFutureObjFunc(opt_params[0],opt_params[1],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "6202365/SUE56C4B": {
     "author": [
      {
       "family": "Fagereng",
       "given": "Andreas"
      },
      {
       "family": "Holm",
       "given": "Martin B."
      },
      {
       "family": "Natvik",
       "given": "Gisle J."
      }
     ],
     "genre": "discussion paper",
     "id": "6202365/SUE56C4B",
     "issued": {
      "year": 2017
     },
     "publisher": "Statistics Norway",
     "title": "MPC Heterogeneity and Household Balance Sheets",
     "type": "report"
    }
   }
  },
  "jupytext": {
   "cell_metadata_filter": "collapsed,code_folding",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
